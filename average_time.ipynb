{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_content_domains = ['www.google.com', 'www.facebook.com', 'www.twitter.com']\n",
    "number_of_days_prior = 1\n",
    "purchase_qualifier = 'AND domain LIKE \"%amazon.com%'\n",
    "list_of_purchases = cleaned_data[0:100]\n",
    "\n",
    "contentdomains = {x:None for x in list_of_content_domains}\n",
    "\n",
    "\n",
    "user_ids = list_of_purchases['user_id'].unique()  \n",
    "\n",
    "for domain in list_of_content_domains:\n",
    "\n",
    "    grand_mean = datetime.timedelta(seconds=0)\n",
    "        \n",
    "    for user in user_ids:\n",
    "\n",
    "        time_domain=dict()\n",
    "        fre_domain=dict()\n",
    "        user_times = {x:None for x in contentdomains.keys()}\n",
    "        user_purchases = list_of_purchases.loc[list_of_purchases['user_id']==user]\n",
    "\n",
    "        for created_date in user_purchases['created_date']:\n",
    "                    \n",
    "            last_x_query = '''SELECT id, user_id, url, created_date, title FROM e_url_map WHERE user_id = {0}\\\n",
    "            AND created_date BETWEEN '{1}' - INTERVAL 7 DAY AND '{1}' \\\n",
    "            AND domain LIKE '%{2}%' ORDER BY created_date DESC  '''\\\n",
    "            .format(user,created_date,domain)\n",
    "            cursor.execute(last_x_query)\n",
    "            last_x_days = pd.DataFrame(cursor.fetchall(), columns = ('id', 'user_id', 'url', 'created_date', 'title'))\n",
    "            if len(last_x_days)>0:\n",
    "                \n",
    "                TIMEDI=created_date - last_x_days['created_date'][0]\n",
    "                \n",
    "                if domain in time_domain:\n",
    "                    time_domain[domain]=time_domain[domain]+TIMEDI\n",
    "                    fre_domain[domain]=fre_domain[domain]+1\n",
    "                else:                   \n",
    "                    time_domain[domain]=TIMEDI\n",
    "                    fre_domain[domain]=1\n",
    "            else:\n",
    "                pass\n",
    "        try:\n",
    "            user_ave=time_domain[domain]/fre_domain[domain]\n",
    "            grand_mean = grand_mean + user_ave\n",
    "        except:\n",
    "            pass\n",
    "    grand_mean = grand_mean/len(user_ids)\n",
    "    print( domain, grand_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import mysql.connector\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import time\\n\",\n",
    "    \"import datetime\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 147,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"cnx = mysql.connector.connect(user='openupadmin', password='6C7E2F760ABFF371',\\n\",\n",
    "    \"                              host='openupdb.cxzofl0nts6g.us-east-1.rds.amazonaws.com', port = 3306,\\n\",\n",
    "    \"                              database='Openup_db')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 148,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"cursor = cnx.cursor()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 92,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"cursor.execute(query)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 93,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"data = pd.DataFrame(cursor.fetchall())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# All user purchase data, return cleaned data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 162,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"query = \\\"SELECT id, user_id, url, title, domain, created_date FROM e_url_map WHERE has_thank_you_confirmation = 1 AND is_beauty=1 AND user_id > 50001\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 163,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"cursor.execute(query)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 164,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"data = pd.DataFrame(cursor.fetchall(),columns = ['id', 'user_id', 'url', 'title', 'domain', 'created_date'])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 165,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# this function takes a series of PURCHASE TIMES and returns the indices of urls that are no less than delta \\n\",\n",
    "    \"# minutes apart\\n\",\n",
    "    \"\\n\",\n",
    "    \"def clean_checkout_repeats(userdata, delta):\\n\",\n",
    "    \"    cleaned_indices = []\\n\",\n",
    "    \"    user_index = list(userdata.index)\\n\",\n",
    "    \"    for count, index in enumerate(user_index):\\n\",\n",
    "    \"        if user_index[count] > -1 and user_index[count] < max(user_index):\\n\",\n",
    "    \"            if (userdata['created_date'][user_index[count]] + datetime.timedelta(minutes = delta) < userdata['created_date'][user_index[count + 1]])\\\\\\n\",\n",
    "    \"            or (userdata['domain'][user_index[count]] != userdata['domain'][user_index[count+1]]):\\n\",\n",
    "    \"                cleaned_indices.append(user_index[count])\\n\",\n",
    "    \"                \\n\",\n",
    "    \"    return userdata.loc[cleaned_indices,:]\\n\",\n",
    "    \"    #return indices where row + 1 and -1 > delta\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 166,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"scrolled\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"cleaned_data = pd.DataFrame(columns = ['id', 'user_id', 'url', 'title', 'domain', 'created_date']) \\n\",\n",
    "    \"     \\n\",\n",
    "    \"for user in data['user_id'].unique():\\n\",\n",
    "    \"    cleaned_data = pd.concat((cleaned_data,clean_checkout_repeats(data.loc[data['user_id']==user], 60)))\\n\",\n",
    "    \"    \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 167,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"461\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 167,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"len(cleaned_data['user_id'].unique())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# Function to determine average time between domain and purchase\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# version 2\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 171,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"www.yahoo.com 0 days 04:52:07.125000\\n\",\n",
    "      \"10.140075206756592\\n\",\n",
    "      \"www.huffingtonpost.com 1 days 12:54:31.072000\\n\",\n",
    "      \"20.074867010116577\\n\",\n",
    "      \"www.refinery29.com 1 days 05:06:22.922872\\n\",\n",
    "      \"30.26970911026001\\n\",\n",
    "      \"www.cnn.com 0 days 14:41:31.779761\\n\",\n",
    "      \"40.191296339035034\\n\",\n",
    "      \"www.elle.com 0 days 17:45:52.750000\\n\",\n",
    "      \"50.516502141952515\\n\",\n",
    "      \"www.cosmopolitan.com 0:00:00\\n\",\n",
    "      \"60.728652238845825\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"tic = time.time()\\n\",\n",
    "    \"\\n\",\n",
    "    \"list_of_content_domains = ['www.yahoo.com', 'www.huffingtonpost.com', 'www.refinery29.com', 'www.cnn.com', 'www.elle.com'\\\\\\n\",\n",
    "    \"                           , 'www.cosmopolitan.com']\\n\",\n",
    "    \"number_of_days_prior = 1\\n\",\n",
    "    \"purchase_qualifier = 'AND domain LIKE \\\"%amazon.com%'\\n\",\n",
    "    \"list_of_purchases = cleaned_data[0:200]\\n\",\n",
    "    \"\\n\",\n",
    "    \"contentdomains = {x:None for x in list_of_content_domains}\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"user_ids = list_of_purchases['user_id'].unique()  \\n\",\n",
    "    \"\\n\",\n",
    "    \"for domain in list_of_content_domains:\\n\",\n",
    "    \"\\n\",\n",
    "    \"    grand_mean = datetime.timedelta(seconds=0)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    for user in user_ids:\\n\",\n",
    "    \"\\n\",\n",
    "    \"        time_domain=dict()\\n\",\n",
    "    \"        fre_domain=dict()\\n\",\n",
    "    \"        user_times = {x:None for x in contentdomains.keys()}\\n\",\n",
    "    \"        user_purchases = list_of_purchases.loc[list_of_purchases['user_id']==user]\\n\",\n",
    "    \"\\n\",\n",
    "    \"        for created_date in user_purchases['created_date']:\\n\",\n",
    "    \"                    \\n\",\n",
    "    \"            last_x_query = '''SELECT id, user_id, url, created_date, title FROM e_url_map WHERE user_id = {0}\\\\\\n\",\n",
    "    \"            AND created_date BETWEEN '{1}' - INTERVAL 7 DAY AND '{1}' \\\\\\n\",\n",
    "    \"            AND domain LIKE '%{2}%' ORDER BY created_date DESC  '''\\\\\\n\",\n",
    "    \"            .format(user,created_date,domain)\\n\",\n",
    "    \"            cursor.execute(last_x_query)\\n\",\n",
    "    \"            last_x_days = pd.DataFrame(cursor.fetchall(), columns = ('id', 'user_id', 'url', 'created_date', 'title'))\\n\",\n",
    "    \"            if len(last_x_days)>0:\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                TIMEDI=created_date - last_x_days['created_date'][0]\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                if domain in time_domain:\\n\",\n",
    "    \"                    time_domain[domain]=time_domain[domain]+TIMEDI\\n\",\n",
    "    \"                    fre_domain[domain]=fre_domain[domain]+1\\n\",\n",
    "    \"                else:                   \\n\",\n",
    "    \"                    time_domain[domain]=TIMEDI\\n\",\n",
    "    \"                    fre_domain[domain]=1\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                pass\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            user_ave=time_domain[domain]/fre_domain[domain]\\n\",\n",
    "    \"            grand_mean = grand_mean + user_ave\\n\",\n",
    "    \"        except:\\n\",\n",
    "    \"            pass\\n\",\n",
    "    \"    grand_mean = grand_mean/len(user_ids)\\n\",\n",
    "    \"    print( domain, grand_mean)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    toc = time.time()-tic\\n\",\n",
    "    \"    print(toc)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.5.2\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 0\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
