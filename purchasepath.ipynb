{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user='openupadmin', password='6C7E2F760ABFF371',\n",
    "                              host='openupdb.cxzofl0nts6g.us-east-1.rds.amazonaws.com', port = 3306,\n",
    "                              database='Openup_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = ('SELECT id, user_id, url, created_date FROM e_url_map WHERE is_beauty = 1 AND has_thank_you_confirmation = 1 AND user_id > 50577 GROUP BY user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2a4732ecce4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'url'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'created_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.columns = ['id', 'user_id', 'url', 'created_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pasturls = pd.DataFrame(columns = ['id', 'user_id', 'url', 'domain', 'created_date'])\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "for (idx, row) in data.loc[:,['user_id', 'created_date']].iterrows():\n",
    "    date = row[1]\n",
    "    user_id = row[0]\n",
    "    query = ('''SELECT id, user_id, url, domain, created_date FROM e_url_map WHERE is_publisher = 1 AND\n",
    "    user_id = {0} AND DATE(created_date) BETWEEN DATE('{1}') - INTERVAL 1 DAY AND DATE('{1}')'''.format(user_id, date))\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    tempdata = pd.DataFrame(cursor.fetchall())\n",
    "    try: \n",
    "        tempdata.columns = ['id', 'user_id', 'url', 'domain', 'created_date']\n",
    "        pasturls = pd.concat((pasturls,tempdata))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elapsed = toc - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pasturls.groupby('domain').count().to_csv('is_jewelry_domain_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pasturls.to_csv('testpublishers_clinique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pasturls.groupby(['domain','user_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pasturls.groupby(['domain','user_id']).count().to_excel('is_beauty_domain_counts.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AMAZON PURCHASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = ('SELECT id, user_id, url, created_date, title FROM e_url_map WHERE title LIKE \"Amazon.com Thanks You\" AND user_id > 50577')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amazonbuy = pd.DataFrame(cursor.fetchall())\n",
    "amazonbuy.columns = ['id', 'user_id', 'url', 'created_date', 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2221"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#317 users\n",
    "len(amazonbuy['user_id'].unique())\n",
    "\n",
    "#made 2184 purchases\n",
    "len(amazonbuy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLS THEY SAW BEFORE THE PURCHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchasedata = pd.DataFrame(columns = ['id','user_id','url', 'created_date','title'], index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (idx,row) in amazonbuy[['user_id', 'created_date']][0:5].iterrows():\n",
    "    user_id = row[0]\n",
    "    created_date = row[1]\n",
    "    query = ('''SELECT id, user_id, url, created_date, title FROM e_url_map WHERE user_id = {0}\\\n",
    "    AND DATE(created_date) BETWEEN DATE('{1}') - INTERVAL 1 HOUR AND DATE('{1}')'''.format(user_id,created_date))\n",
    "    cursor.execute(query)\n",
    "    tempdata = pd.DataFrame(cursor.fetchall(), columns = ['id','user_id','url', 'created_date','title'], index=None)\n",
    "    purchasedata = pd.concat((purchasedata,tempdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  user_id                                                url  \\\n",
      "0     323443.0  50738.0  https://mail.google.com/mail/u/0/#starred/1575...   \n",
      "1     323448.0  50738.0  https://www.google.com/url?hl=en&q=http://mail...   \n",
      "2     323449.0  50738.0  https://mail.google.com/mail/u/0/#starred/1574...   \n",
      "3     323450.0  50738.0  https://subscribe.hearstmags.com/subscribe/spl...   \n",
      "4     323451.0  50738.0  https://subscribe.hearstmags.com/subscribe/spl...   \n",
      "5     323452.0  50738.0  https://subscribe.hearstmags.com/subscribe/off...   \n",
      "6     323453.0  50738.0          https://mail.google.com/mail/u/0/#starred   \n",
      "7     323457.0  50738.0             http://open-up.io/extensions/download/   \n",
      "8     323458.0  50738.0            https://mail.google.com/mail/u/2/#inbox   \n",
      "9     323459.0  50738.0  https://www.google.com/url?hl=en&q=https://e.h...   \n",
      "10    323460.0  50738.0  https://mail.google.com/mail/u/2/#inbox/157614...   \n",
      "11    323461.0  50738.0  https://www.hollisterco.com/webapp/wcs/stores/...   \n",
      "12    323462.0  50738.0                   https://mail.google.com/mail/u/1   \n",
      "13    323463.0  50738.0          https://mail.google.com/mail/u/0/#starred   \n",
      "14    323464.0  50738.0            https://mail.google.com/mail/u/1/#inbox   \n",
      "15    323465.0  50738.0            https://mail.google.com/mail/u/2/#inbox   \n",
      "16    323466.0  50738.0            https://mail.google.com/mail/u/1/#inbox   \n",
      "17    323467.0  50738.0  https://www.hollisterco.com/webapp/wcs/stores/...   \n",
      "18    323468.0  50738.0            https://mail.google.com/mail/u/2/#inbox   \n",
      "19    323469.0  50738.0  https://www.hollisterco.com/webapp/wcs/stores/...   \n",
      "20    323470.0  50738.0  https://www.hollisterco.com/webapp/wcs/stores/...   \n",
      "21    323471.0  50738.0  https://www.hollisterco.com/webapp/wcs/stores/...   \n",
      "22    323472.0  50738.0  https://www.hollisterco.com/shop/us/guys-tops-...   \n",
      "23    323483.0  50738.0  https://www.hollisterco.com/webapp/wcs/stores/...   \n",
      "24    323485.0  50738.0  https://www.hollisterco.com/shop/us/guys-tops-...   \n",
      "25    323526.0  50738.0  http://www.ulta.com/bcrf-gorgeous-way-to-give/...   \n",
      "26    323527.0  50738.0   https://app.promo.eprize.com/agorgeouswaytogive/   \n",
      "27    323528.0  50738.0   http://www.ulta.com/ulta/stores/storelocator.jsp   \n",
      "28    323529.0  50738.0   http://www.ulta.com/ulta/stores/storelocator.jsp   \n",
      "29    323530.0  50738.0   https://app.promo.eprize.com/agorgeouswaytogive/   \n",
      "...        ...      ...                                                ...   \n",
      "1143  606187.0  50689.0  http://greatist.com/eat/healthy-breakfast-sand...   \n",
      "1144  606188.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1145  606190.0  50689.0  http://peasandcrayons.com/2016/02/key-lime-pie...   \n",
      "1146  606191.0  50689.0  https://secure.bhg.com/common/profile/regStep1...   \n",
      "1147  606192.0  50689.0  http://peasandcrayons.com/2016/02/key-lime-pie...   \n",
      "1148  606193.0  50689.0  http://greatist.com/eat/healthy-breakfast-sand...   \n",
      "1149  606199.0  50689.0  http://peasandcrayons.com/2016/02/key-lime-pie...   \n",
      "1150  606200.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1151  606201.0  50689.0  http://peasandcrayons.com/2016/02/key-lime-pie...   \n",
      "1152  606202.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1153  606203.0  50689.0  http://peasandcrayons.com/2016/02/key-lime-pie...   \n",
      "1154  606204.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1155  606205.0  50689.0  http://peasandcrayons.com/2016/02/key-lime-pie...   \n",
      "1156  606206.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1157  606207.0  50689.0  http://www.cottercrunch.com/paleo-chocolate-co...   \n",
      "1158  606208.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1159  606210.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1160  606211.0  50689.0  http://happyhealthymotivated.com/raw-vegan-bro...   \n",
      "1161  606212.0  50689.0  http://www.joyfulhealthyeats.com/bake-dark-cho...   \n",
      "1162  606213.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1163  606214.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1164  606215.0  50689.0  http://www.joyfulhealthyeats.com/bake-dark-cho...   \n",
      "1165  606216.0  50689.0  http://www.thehealthymaven.com/2015/10/strawbe...   \n",
      "1166  606217.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1167  606220.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1168  606221.0  50689.0  http://www.thehealthymaven.com/2015/10/strawbe...   \n",
      "1169  606223.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1170  606224.0  50689.0  https://www.pinterest.com/pin/find/?url=http%3...   \n",
      "1171  606269.0  50689.0                             https://www.yahoo.com/   \n",
      "1172  606270.0  50689.0  https://mg.mail.yahoo.com/neo/launch?.rand=3in...   \n",
      "\n",
      "            created_date                                              title  \n",
      "0    2016-09-25 12:29:47   Got Style? Get Swag - laritza0@gmail.com - Gmail  \n",
      "1    2016-09-25 12:30:09                                                     \n",
      "2    2016-09-25 12:30:10  You Could Win $1,000 to Splurge on The Ultimat...  \n",
      "3    2016-09-25 12:30:13                 Fall Wardrobe Shopping Sweepstakes  \n",
      "4    2016-09-25 12:30:15                 Fall Wardrobe Shopping Sweepstakes  \n",
      "5    2016-09-25 12:30:29                 Fall Wardrobe Shopping Sweepstakes  \n",
      "6    2016-09-25 12:30:31               Starred - laritza0@gmail.com - Gmail  \n",
      "7    2016-09-25 12:31:34                                             Openup  \n",
      "8    2016-09-25 12:31:37   Inbox (614) - laritzaramos1234@gmail.com - Gmail  \n",
      "9    2016-09-25 12:32:03                                                     \n",
      "10   2016-09-25 12:32:04  Ready... Set... Hunt! The #HCOSCAVENGERHUNT st...  \n",
      "11   2016-09-25 12:32:08                                    HollisterCo.com  \n",
      "12   2016-09-25 12:32:09                                                     \n",
      "13   2016-09-25 12:32:10               Starred - laritza0@gmail.com - Gmail  \n",
      "14   2016-09-25 12:32:13       Inbox (2,988) - clancy8890@gmail.com - Gmail  \n",
      "15   2016-09-25 12:32:14   Inbox (614) - laritzaramos1234@gmail.com - Gmail  \n",
      "16   2016-09-25 12:32:15       Inbox (2,988) - clancy8890@gmail.com - Gmail  \n",
      "17   2016-09-25 12:32:27                                    HollisterCo.com  \n",
      "18   2016-09-25 12:32:28   Inbox (614) - laritzaramos1234@gmail.com - Gmail  \n",
      "19   2016-09-25 12:32:29                                    HollisterCo.com  \n",
      "20   2016-09-25 12:32:38                                    HollisterCo.com  \n",
      "21   2016-09-25 12:32:47                                    HollisterCo.com  \n",
      "22   2016-09-25 12:32:59  Guys Must-Have Colorblock Raglan T-Shirt | Guy...  \n",
      "23   2016-09-25 12:33:59                                    HollisterCo.com  \n",
      "24   2016-09-25 12:34:07  Guys Must-Have Colorblock Raglan T-Shirt | Guy...  \n",
      "25   2016-09-25 12:37:09  www.ulta.com/bcrf-gorgeous-way-to-give/rules/U...  \n",
      "26   2016-09-25 12:37:09                             A Gorgeous Way to Give  \n",
      "27   2016-09-25 12:37:09                   Ulta Store Locator | Ulta Beauty  \n",
      "28   2016-09-25 12:37:09                   Ulta Store Locator | Ulta Beauty  \n",
      "29   2016-09-25 12:37:09                             A Gorgeous Way to Give  \n",
      "...                  ...                                                ...  \n",
      "1143 2016-10-02 09:15:27  Breakfast Sandwich Recipes That Are Actually H...  \n",
      "1144 2016-10-02 09:15:27           Pinterest • The world’s catalog of ideas  \n",
      "1145 2016-10-02 09:15:42       Key Lime Pie Energy Bites - Peas And Crayons  \n",
      "1146 2016-10-02 09:15:42                                       Registration  \n",
      "1147 2016-10-02 09:15:46       Key Lime Pie Energy Bites - Peas And Crayons  \n",
      "1148 2016-10-02 09:15:49  Breakfast Sandwich Recipes That Are Actually H...  \n",
      "1149 2016-10-02 09:17:06       Key Lime Pie Energy Bites - Peas And Crayons  \n",
      "1150 2016-10-02 09:17:07           Pinterest • The world’s catalog of ideas  \n",
      "1151 2016-10-02 09:17:34       Key Lime Pie Energy Bites - Peas And Crayons  \n",
      "1152 2016-10-02 09:17:39           Pinterest • The world’s catalog of ideas  \n",
      "1153 2016-10-02 09:17:46       Key Lime Pie Energy Bites - Peas And Crayons  \n",
      "1154 2016-10-02 09:17:49           Pinterest • The world’s catalog of ideas  \n",
      "1155 2016-10-02 09:17:50       Key Lime Pie Energy Bites - Peas And Crayons  \n",
      "1156 2016-10-02 09:18:17           Pinterest • The world’s catalog of ideas  \n",
      "1157 2016-10-02 09:18:42  Chocolate Coconut Pistachio Bites {Paleo and V...  \n",
      "1158 2016-10-02 09:18:46           Pinterest • The world’s catalog of ideas  \n",
      "1159 2016-10-02 09:19:14           Pinterest • The world’s catalog of ideas  \n",
      "1160 2016-10-02 09:19:35                     Raw Vegan Brownie Bites Recipe  \n",
      "1161 2016-10-02 09:19:39  No Bake Dark Chocolate Coconut Almond Butter E...  \n",
      "1162 2016-10-02 09:19:43           Pinterest • The world’s catalog of ideas  \n",
      "1163 2016-10-02 09:20:02           Pinterest • The world’s catalog of ideas  \n",
      "1164 2016-10-02 09:20:32  No Bake Dark Chocolate Coconut Almond Butter E...  \n",
      "1165 2016-10-02 09:20:41  Strawberry Cheesecake Swirl Energy Balls - The...  \n",
      "1166 2016-10-02 09:20:42           Pinterest • The world’s catalog of ideas  \n",
      "1167 2016-10-02 09:21:10           Pinterest • The world’s catalog of ideas  \n",
      "1168 2016-10-02 09:21:36  Strawberry Cheesecake Swirl Energy Balls - The...  \n",
      "1169 2016-10-02 09:21:43           Pinterest • The world’s catalog of ideas  \n",
      "1170 2016-10-02 09:22:11           Pinterest • The world’s catalog of ideas  \n",
      "1171 2016-10-02 09:35:53                                              Yahoo  \n",
      "1172 2016-10-02 09:36:06                       jetflybutterfly - Yahoo Mail  \n",
      "\n",
      "[4042 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#purchasedata.to_excel('purchasedata.xlsx')\n",
    "print(purchasedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHOPPING CART GENERATOR FOR USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cartdict = {x:[pd.DataFrame(columns = ['id','user_id','url', 'created_date','title'])] for x in amazonbuy['user_id']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractcartitems(user_id):\n",
    "    #get list of IDs with shopping carts\n",
    "    query1 = '''SELECT id FROM e_url_map WHERE user_id = {0} and TITLE LIKE\n",
    "    \"Amazon.com Shopping Cart\"'''.format(user_id)\n",
    "    \n",
    "    cursor.execute(query1)\n",
    "    ids = [x[0] for x in cursor.fetchall()]\n",
    "    ids = tuple(ids)\n",
    "    \n",
    "    #pull previous rows from above\n",
    "    \n",
    "    itemids = []\n",
    "    for idz in ids:\n",
    "        query2 = '''SELECT id from e_url_map WHERE\n",
    "        id = (SELECT MAX(id) from e_url_map WHERE id < {1} AND user_id = {0})'''.format(user_id, idz)\n",
    "        cursor.execute(query2)\n",
    "        itemids.append(cursor.fetchall()[0][0])\n",
    "        \n",
    "    itemids = tuple(itemids)\n",
    "    \n",
    "    \n",
    "    query3 = '''SELECT id, user_id, url, created_date, title FROM e_url_map WHERE user_id = {0} and id IN {1}'''.format(user_id, itemids)\n",
    "    cursor.execute(query3)\n",
    "    \n",
    "    return pd.DataFrame(cursor.fetchall(), columns = ['id','user_id','url', 'created_date','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extractcartitems(amazonbuy['user_id'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amazonbuy['user_id'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FILTERING SHOPPING URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''SELECT DISTINCT(url), title, domain, created_date FROM e_url_map WHERE has_thank_you_confirmation = 1 AND user_id = 50024'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userdata = pd.DataFrame(cursor.fetchall(), columns = ['url', 'title', 'domain', 'created_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userdata['created_date'][0] + datetime.timedelta(minutes = +5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userdata['created_date'][0] + datetime.timedelta(minutes = 5) < userdata['created_date'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All user purchase data, return cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    import sys\n",
    "    \n",
    "    def clean_checkout_repeats(userdata, delta):\n",
    "        cleaned_indices = []\n",
    "        user_index = list(userdata.index)\n",
    "        for count, index in enumerate(user_index):\n",
    "            if user_index[count] > -1 and user_index[count] < max(user_index):\n",
    "                if (userdata['created_date'][user_index[count]] + datetime.timedelta(minutes = delta) < userdata['created_date'][user_index[count + 1]])\\\n",
    "                or (userdata['domain'][user_index[count]] != userdata['domain'][user_index[count+1]]):\n",
    "                    cleaned_indices.append(user_index[count])\n",
    "\n",
    "        return userdata.loc[cleaned_indices,:]\n",
    "\n",
    "    data = pd.read_csv(sys.argv[1], columns = ['user_id', 'url', 'title', 'domain', 'created_date']) \n",
    "     \n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "    data.loc[:,['created_date']] = [datetime.datetime.strptime(x, format) for x in data['created_date']]\n",
    "     \n",
    "    cleaned_data = pd.DataFrame(columns = ['user_id', 'url', 'title', 'domain', 'created_date']) \n",
    "     \n",
    "    for user in data['user_id'].unique():\n",
    "        pd.concat(cleaned_data,clean_checkout_repeats(data.loc[data['user_id']==user], 5))\n",
    "        \n",
    "#if __name__ == \"__main__\":\n",
    "#\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT id, user_id, url, title, domain, created_date FROM e_url_map WHERE has_thank_you_confirmation = 1 AND user_id > 50001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(cursor.fetchall(),columns = ['id', 'user_id', 'url', 'title', 'domain', 'created_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this function takes a series of PURCHASE TIMES and returns the indices of urls that are no less than delta \n",
    "# minutes apart\n",
    "\n",
    "def clean_checkout_repeats(userdata, delta):\n",
    "    cleaned_indices = []\n",
    "    user_index = list(userdata.index)\n",
    "    for count, index in enumerate(user_index):\n",
    "        if user_index[count] > -1 and user_index[count] < max(user_index):\n",
    "            if (userdata['created_date'][user_index[count]] + datetime.timedelta(minutes = delta) < userdata['created_date'][user_index[count + 1]])\\\n",
    "            or (userdata['domain'][user_index[count]] != userdata['domain'][user_index[count+1]]):\n",
    "                cleaned_indices.append(user_index[count])\n",
    "                \n",
    "    return userdata.loc[cleaned_indices,:]\n",
    "    #return indices where row + 1 and -1 > delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cleaned_data = pd.DataFrame(columns = ['id', 'user_id', 'url', 'title', 'domain', 'created_date']) \n",
    "     \n",
    "for user in data['user_id'].unique():\n",
    "    cleaned_data = pd.concat((cleaned_data,clean_checkout_repeats(data.loc[data['user_id']==user], 60)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(cleaned_data['user_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Function to determine average time between domain and purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def average_time_to_purchase(domain_of_content, number_of_days_prior, domain_of_purchase) \n",
    "\n",
    "CONTENTDOMAIN, PURCHASEDOMAIN, DAYSPRIOR ARE ARGUMENTS\n",
    "\n",
    "CONTENTDOMAINS={X:0, Y:0, Z:0}\n",
    "\n",
    "USER_IDS = (FROM PURCHASEDATA W/ PURCHASEDOMAIN)\n",
    "\n",
    "FOR USER IN USER_IDS:\n",
    "    USER_TIMES = {X FOR X IN COTENTDOMAINS.KEYS}\n",
    "    USER_PURCHASE_DATA = SQL QUERY W/ PURCHASEDOMAIN \n",
    "    \n",
    "    FOR PURCHASE IN USER_PURCHASE_DATA:\n",
    "        LAST_X_DAYS = SQL QUERY W/ DAYSPRIOR\n",
    "        IF DOMAIN IN LAST_X_DAYS:\n",
    "            FIND TIMEDIFFERENCE\n",
    "            APPEND TO USER_TIMES[CONTENTDOMAIN]\n",
    "            \n",
    "    FOR DOMAIN IN USER_TIMES, AVERAGE TIME\n",
    "    \n",
    "AVERAGE ACROSS ALL USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def average_time_to_purchase(list_of_content_domains, number_of_days_prior, domain_of_purchase):\n",
    "    contentdomains = {x:None for x in list_of_content_domains}\n",
    "    \n",
    "    purchase_query = \"SELECT id, user_id, url, title, domain, created_date FROM e_url_map WHERE has_thank_you_confirmation = 1 \\\n",
    "    AND user_id > 50001\"\n",
    "    cursor.execute(purchase_query)\n",
    "    user_ids = unique(cursor.fetchall())\n",
    "    \n",
    "    for user in user_id:\n",
    "        user_times = {x:None for x in contentdomains.keys()}\n",
    "        user_purchase_query = \"SELECT id, user_id, url, title, domain, created_date FROM e_url_map WHERE \\\n",
    "        has_thank_you_confirmation = 1 AND user_id = {0}\".format(user)\n",
    "        cursor.execute(user_purchase_query)\n",
    "        user_purchase_data = pd.DataFrame(cursor.fetchall())\n",
    "        \n",
    "        for purchase in user_purchase_data['id']:\n",
    "            last_x_query = ('''SELECT id, user_id, url, created_date, title FROM e_url_map WHERE user_id = {0}\\\n",
    "            AND DATE(created_date) BETWEEN DATE('{1}') - INTERVAL 1 HOUR AND DATE('{1}')'''.format(user_id,created_date))\n",
    "\n",
    "            cursor.execute(last_x_query)\n",
    "            last_x_days = pd.DataFrame(cursor.fetchall())\n",
    "            if domain in ...:\n",
    "                #FIND DIFFERNECE IN TIME\n",
    "                user_times['domain'].append(TIME)\n",
    "                \n",
    "   #FOR DOMAIN IN USER_TIMES, AVERAGE TIME\n",
    "    \n",
    "#AVERAGE ACROSS ALL USERS        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_of_content_domains = ['www.elle.com', 'www.nytimes.com', 'www.bbc.com']\n",
    "number_of_days_prior = 1\n",
    "purchase_qualifier = 'AND domain LIKE \"%amazon.com%'\n",
    "list_of_purchases = cleaned_data[0:10]\n",
    "\n",
    "contentdomains = {x:None for x in list_of_content_domains}\n",
    "        \n",
    "user_ids = list_of_purchases['user_id'].unique()\n",
    "    \n",
    "for user in user_ids:\n",
    "    user_times = {x:None for x in contentdomains.keys()}\n",
    "    user_purchases = list_of_purchases.loc[list_of_purchases['user_id']==user]\n",
    "    for purchase_id,created_date in zip(user_purchases['id'],user_purchases['created_date']):\n",
    "        last_x_query = ('''SELECT id, user_id, url, created_date, title FROM e_url_map WHERE id = {0}\\\n",
    "        #AND DATE(created_date) BETWEEN DATE('{1}') - INTERVAL 1 HOUR AND DATE('{1}')'''.format(purchase_id,created_date))\n",
    "        cursor.execute(last_x_query)\n",
    "        last_x_days = pd.DataFrame(cursor.fetchall())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    for purchase in user_purchase_data['id']:\n",
    "        last_x_query = ('''SELECT id, user_id, url, created_date, title FROM e_url_map WHERE user_id = {0}\\\n",
    "        AND DATE(created_date) BETWEEN DATE('{1}') - INTERVAL 1 HOUR AND DATE('{1}')'''.format(user_id,created_date))\n",
    "\n",
    "        #if domain in ...:\n",
    "            #FIND DIFFERNECE IN TIME\n",
    "            #user_times['domain'].append(TIME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_purchases.loc[:,['id','created_date']].iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_x_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
